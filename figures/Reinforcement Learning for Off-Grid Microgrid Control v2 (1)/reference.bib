
@article{Leva2019,
author = {Leva, Sonia and Mussettav, Marco and Nespoli, Alfredo and Ogliari, Emanuele},
doi = {10.1109/ptc.2019.8810921},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/08810921.pdf:pdf},
pages = {1--5},
title = {{PV power forecasting improvement by means of a selective ensemble approach}},
year = {2019}
}
@article{Palma-Behnke2013,
abstract = {A novel energy management system (EMS) based on a rolling horizon (RH) strategy for a renewable-based microgrid is proposed. For each decision step, a mixed integer optimization problem based on forecasting models is solved. The EMS provides online set points for each generation unit and signals for consumers based on a demand-side management (DSM) mechanism. The proposed EMS is implemented for a microgrid composed of photovoltaic panels, two wind turbines, a diesel generator and an energy storage system. A coherent forecast information scheme and an economic comparison framework between the RH and the standard unit commitment (UC) are proposed. Solar and wind energy forecasting are based on phenomenological models with updated data. A neural network for two-day-ahead electric consumption forecasting is also designed. The system is tested using real data sets from an existent microgrid in Chile (ESUSCON). The results based on different operation conditions show the economic sense of the proposal. A full practical implementation of the system for ESUSCON is envisioned.},
author = {Palma-Behnke, Rodrigo and Benavides, Carlos and Lanas, Fernando and Severino, Bernardo and Reyes, Lorenzo and Llanos, Jacqueline and Saez, Doris},
doi = {10.1109/TSG.2012.2231440},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/Palmaetal2013.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Demand-side management,energy management system,microgrid,photovoltaic,rolling horizon,wind turbine},
number = {2},
pages = {996--1006},
title = {{A microgrid energy management system based on the rolling horizon strategy}},
volume = {4},
year = {2013}
}
@article{Amjady2010,
abstract = {Microgrids are a rapidly growing sector of smart grids, which will be an essential component in the trend toward distributed electricity generation. In the operation of a microgrid, forecasting the short-term load is an important task. With a more accurate short-term loaf forecast (STLF), the microgrid can enhance the management of its renewable and conventional resources and improve the economics of energy trade with electricity markets. However, STLF for microgrids is a complex forecast process, mainly because of the highly nonsmooth and nonlinear behavior of the load time series. In this paper, characteristics of the load time series of a typical microgrid are discussed and the differences with the load time series of traditional power systems are described. In addition, a new bilevel prediction strategy is proposed for STLF of microgrids. The proposed strategy is composed of a feature selection technique and a forecast engine (including neural network and evolutionary algorithm) in the lower level as the forecaster and an enhanced differential evolution algorithm in the upper level for optimizing the performance of the forecaster. The effectiveness of the proposed prediction strategy is evaluated by the real-life data of a university campus in Canada. {\textcopyright} 2010 IEEE.},
author = {Amjady, Nima and Keynia, Farshid and Zareipour, Hamidreza},
doi = {10.1109/TSG.2010.2078842},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/Nima{\_}MicroGridLOafForeacsting{\_}2010.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Differential evolution algorithm,load forecast,microgrid,neural networks},
number = {3},
pages = {286--294},
title = {{Short-term load forecast of microgrids by a new bilevel prediction strategy}},
volume = {1},
year = {2010}
}
@article{Parisio2017,
abstract = {{\textcopyright} 2017 IEEE. Microgrids are subsystems of the distribution grid operating as a single controllable system either connected or isolated from the grid. In this paper, a novel cooperative model predictive control (MPC) framework is proposed for urban districts comprising multiple microgrids sharing certain distributed energy resources (DERs). The operation of the microgrids, along with the shared DER, are coordinated such that the available flexibility sources are optimised and a common goal is achieved, e.g., minimizing energy exchanged with the distribution grid and the overall energy costs. Each microgrid is equipped with an MPC-based energy management system, responsible for optimally controlling flexible loads, heating systems, and local generation devices based on end-user preferences, weather-dependent generation and demand forecasts, energy prices, and technical and operational constraints. The proposed coordination algorithm is distributed and guarantees constraints satisfaction, cooperation among microgrids and fairness in the use of the shared resources, while addressing the issue of scalability of energy management in an urban district. Furthermore, the proposed framework guarantees an agreed cost saving to each microgrid. The described method is implemented and evaluated in a virtual testing environment that integrates accurate simulators of the microgrids. Numerical experiments show the feasibility, the computational benefits, and the effectiveness of the proposed approach.},
author = {Parisio, Alessandra and Wiezorek, Christian and Kynt{\"{a}}j{\"{a}}, Timo and Elo, Joonas and Strunz, Kai and Johansson, Karl Henrik},
doi = {10.1109/TSG.2017.2726941},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/08004502.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Model predictive control,demand response,distributed optimization,energy management systems,flexibility services,mixed integer linear programming},
number = {6},
pages = {3066--3074},
title = {{Cooperative MPC-Based Energy Management for Networked Microgrids}},
volume = {8},
year = {2017}
}
@article{Kuznetsova2013,
abstract = {We consider a microgrid for energy distribution, with a local consumer, a renewable generator (wind turbine) and a storage facility (battery), connected to the external grid via a transformer. We propose a 2 steps-ahead reinforcement learning algorithm to plan the battery scheduling, which plays a key role in the achievement of the consumer goals. The underlying framework is one of multi-criteria decision-making by an individual consumer who has the goals of increasing the utilization rate of the battery during high electricity demand (so as to decrease the electricity purchase from the external grid) and increasing the utilization rate of the wind turbine for local use (so as to increase the consumer independence from the external grid). Predictions of available wind power feed the reinforcement learning algorithm for selecting the optimal battery scheduling actions. The embedded learning mechanism allows to enhance the consumer knowledge about the optimal actions for battery scheduling under different time-dependent environmental conditions. The developed framework gives the capability to intelligent consumers to learn the stochastic environment and make use of the experience to select optimal energy management actions. {\textcopyright} 2013 Elsevier Ltd.},
author = {Kuznetsova, Elizaveta and Li, Yan Fu and Ruiz, Carlos and Zio, Enrico and Ault, Graham and Bell, Keith},
doi = {10.1016/j.energy.2013.05.060},
file = {:C$\backslash$:/Users/jcbou/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuznetsova et al. - 2013 - Reinforcement learning for microgrid energy management.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {Markov chain model,Microgrids,Reinforcement learning,Sensitivity analysis,Smartgrids},
month = {sep},
pages = {133--146},
publisher = {Pergamon},
title = {{Reinforcement learning for microgrid energy management}},
url = {https://www.sciencedirect.com/science/article/pii/S0360544213004817},
volume = {59},
year = {2013}
}
@article{Powell2016,
abstract = {In Part I of this tutorial, we provided a canonical modeling framework for sequential, stochastic optimization (control) problems. A major feature of this framework is a clear separation of the process of modeling a problem, versus the design of policies to solve the problem. In Part II, we provide additional discussion behind some of the more subtle concepts such as the construction of a state variable. We illustrate the modeling process using an energy storage problem. We then create five variations of this problem designed to bring out the features of the different policies. The first four of these problems demonstrate that each of the four classes of policies is best for particular problem characteristics. The fifth policy is a hybrid that illustrates the ability to combine the strengths of multiple policy classes.},
author = {Powell, Warren B. and Meisel, Stephan},
doi = {10.1109/TPWRS.2015.2424980},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/ToRead/07100937.pdf:pdf},
isbn = {0885-8950},
issn = {08858950},
journal = {IEEE Transactions on Power Systems},
keywords = {Approximate dynamic programming,dynamic programming,energy storage,energy systems,optimal control,reinforcement learning,robust optimization,stochastic optimization,stochastic programming},
number = {2},
pages = {1468--1475},
publisher = {IEEE},
title = {{Tutorial on Stochastic Optimization in Energy - Part II: An Energy Storage Illustration}},
volume = {31},
year = {2016}
}
@misc{Curfman2009,
author = {Curfman, Gregory D. and Morrissey, Stephen and Drazen, Jeffrey M.},
booktitle = {New England Journal of Medicine},
doi = {10.1056/NEJMe0902377},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/rgfsg.pdf:pdf},
issn = {15334406},
number = {15},
pages = {1550--1551},
title = {{A Model Predictive Control Approach to Microgrid Operation Optimization}},
volume = {360},
year = {2009}
}
@article{Petrollese2016,
abstract = {This paper presents a novel control strategy for the optimal management of microgrids with high penetration of renewable energy sources and different energy storage systems. The control strategy is based on the integration of optimal generation scheduling with a model predictive control in order to achieve both long and short-term optimal planning. In particular, long-term optimization of the various microgrid components is obtained by the adoption of an optimal generation scheduling, in which a statistical approach is used to take into account weather and load forecasting uncertainties. The real-time management of the microgrid is instead entrusted to a model predictive controller, which has the important feature of using the results obtained by the optimal generation scheduling. The proposed control strategy was tested in a laboratory-scale microgrid present at the University of Seville, which is composed of an electronic power source that emulates a photovoltaic system, a battery bank and a hydrogen production and storage system. Two different experimental tests that simulate a summer and a winter day were carried out over a 24-h period to verify the reliability and performance enhancement of the control system. Results show an effective improvement in performance in terms of reduction of the microgrid operating cost and greater involvement of the hydrogen storage system for the maintenance of a spinning reserve in batteries.},
author = {Petrollese, Mario and Valverde, Luis and Cocco, Daniele and Cau, Giorgio and Guerra, Jos{\'{e}}},
doi = {10.1016/j.apenergy.2016.01.014},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/dd.pdf:pdf},
issn = {03062619},
journal = {Applied Energy},
keywords = {Energy management strategy,Energy storage systems,Hydrogen storage,Renewable energy},
pages = {96--106},
title = {{Real-time integration of optimal generation scheduling with MPC for the energy management of a renewable hydrogen-based microgrid}},
volume = {166},
year = {2016}
}
@article{Leva2017,
abstract = {In this paper an artificial neural network for photovoltaic plant energy forecasting is proposed and analyzed in terms of its sensitivity with respect to the input data sets. Furthermore, the accuracy of the method has been studied as a function of the training data sets and error definitions. The analysis is based on experimental activities carried out on a real photovoltaic power plant accompanied by clear sky model. In particular, this paper deals with the hourly energy prediction for all the daylight hours of the following day, based on 48 hours ahead weather forecast. This is very important due to the predictive features requested by smart grid application: renewable energy sources planning, in particular storage system sizing, and market of energy.},
author = {Leva, S. and Dolara, A. and Grimaccia, F. and Mussetta, M. and Ogliari, E.},
doi = {10.1016/j.matcom.2015.05.010},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/fgnxh.pdf:pdf},
issn = {03784754},
journal = {Mathematics and Computers in Simulation},
keywords = {Artificial neural network,Energy forecasting,Photovoltaic system},
pages = {88--100},
title = {{Analysis and validation of 24 hours ahead neural network forecasting of photovoltaic output power}},
volume = {131},
year = {2017}
}
@article{Powell2016a,
abstract = {There is a wide range of problems in energy systems that require making decisions in the presence of different forms of uncertainty. The fields that address sequential, stochastic decision problems lack a standard canonical modeling framework, with fragmented, competing solution strategies. Recognizing that we will never agree on a single notational system, this two-part tutorial proposes a simple, straightforward canonical model (that is most familiar to people with a control theory background), and introduces four fundamental classes of policies which integrate the competing strategies that have been proposed under names such as control theory, dynamic programming, stochastic programming and robust optimization. Part II of the tutorial illustrates the modeling framework using a simple energy storage problem, where we show that, depending on the problem characteristics, each of the four classes of policies may be best.},
author = {Powell, Warren B. and Meisel, Stephan},
doi = {10.1109/TPWRS.2015.2424974},
file = {:C$\backslash$:/Users/jcbou/Documents/PhD/ToRead/07097741.pdf:pdf},
isbn = {0885-8950 VO - PP},
issn = {08858950},
journal = {IEEE Transactions on Power Systems},
keywords = {Approximate dynamic programming,dynamic programming,energy systems,optimal control,reinforcement learning,robust optimization,stochastic optimization,stochastic programming},
number = {2},
pages = {1459--1467},
title = {{Tutorial on Stochastic Optimization in Energy - Part I: Modeling and Policies}},
volume = {31},
year = {2016}
}


@inproceedings{franccois2016deep,
	title={Deep reinforcement learning solutions for energy microgrids management},
	author={Fran{\c{c}}ois-Lavet, Vincent and Taralla, David and Ernst, Damien and Fonteneau, Rapha{\"e}l},
	booktitle={European Workshop on Reinforcement Learning (EWRL 2016)},
	year={2016}
}

@inproceedings{Boukas2018,
	author = {Boukas, Ioannis and Ernst, Damien and Papavasiliou, Anthony and Corn\'elusse, Bertrand},
	keywords = {deep-q networks,electricity markets,intra-day market,storage devices},
	title = {{Intra-day Bidding Strategies for Storage Devices Using Deep Reinforcement Learning}},
	booktitle={15th International Conference on the European Energy Market},
	volume = {14},
	year = {2018}
}

@article{Dakir2019,
	author = {Dakir, Selmane and Boukas, Ioannis and Lemort, Vincent and Corn\'elusse, Bertrand},
	doi = {10.1109/ptc.2019.8810700},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/2019{\_}Sizing{\_}Dakir{\_}EEEIC.pdf:pdf},
	isbn = {9781538651865},
	mendeley-groups = {mgRL},
	pages = {1--6},
	title = {{Sizing and Operation of an Isolated Microgrid with Cold Storage}},
	year = {2019}
}

@article{Parisio2014,
	abstract = {In this paper we deal with the problem of efficiently optimizing microgrid operations while satisfying a time-varying request and operation constraints. Microgrids are subsystems of the distribution grid comprising sufficient generating resources to operate in isolation from the main grid, in a deliberate and controlled way. The Model Predictive Control (MPC) approach is applied for achieving economic efficiency in microgrid operation management. The method is thus applied to an experimental microgrid located in Athens, Greece: experimental results show the feasibility and the effectiveness of the proposed approach. {\textcopyright} 2013 Elsevier Ltd.},
	author = {Parisio, Alessandra and Rikos, Evangelos and Tzamalis, George and Glielmo, Luigi},
	doi = {10.1016/j.apenergy.2013.10.027},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/1-s2.0-S0306261913008477-main.pdf:pdf},
	issn = {03062619},
	journal = {Applied Energy},
	keywords = {Microgrids,Mixed Integer Linear Programming,Model predictive control,Optimization},
	mendeley-groups = {mgRL},
	pages = {37--46},
	publisher = {Elsevier Ltd},
	title = {{Use of model predictive control for experimental microgrid optimization}},
	url = {http://dx.doi.org/10.1016/j.apenergy.2013.10.027},
	volume = {115},
	year = {2014}
}


@article{Hernandez2014,
	abstract = {The adaptation of energy production to demand has been traditionally very important for utilities in order to optimize resource consumption. This is especially true also in microgrids where many intelligent elements have to adapt their behaviour depending on the future generation and consumption conditions. However, traditional forecasting has been performed only for extremely large areas, such as nations and regions. This work aims at presenting a solution for short-term load forecasting (STLF) in microgrids, based on a three-stage architecture which starts with pattern recognition by a self-organizing map (SOM), a clustering of the previous partition via k-means algorithm, and finally demand forecasting for each cluster with a multilayer perceptron. Model validation was performed with data from a microgrid-sized environment provided by the Spanish company Iberdrola.},
	author = {Hern{\'{a}}ndez, Luis and Baladr{\'{o}}n, Carlos and Aguiar, Javier M. and Carro, Bel{\'{e}}n and S{\'{a}}nchez-Esguevillas, Antonio and Lloret, Jaime},
	doi = {10.1016/j.energy.2014.07.065},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/1-s2.0-S0360544214008871-main.pdf:pdf},
	issn = {03605442},
	journal = {Energy},
	keywords = {Artificial neural network,K-Means algorithm,Microgrid,Pattern recognition,Self-organizing map,Short-term load forecasting},
	mendeley-groups = {mgRL},
	pages = {252--264},
	title = {{Artificial neural networks for short-term load forecasting in microgrids environment}},
	volume = {75},
	year = {2014}
}

@article{Dolara2015,
	abstract = {The electricity produced from renewable energy, in particular from wind and photovoltaic plants, has seen exponential rise in the last decade. Consequently, the prediction of power produced from these plants is fundamental for the reliability, safety and stability of the grid. This paper compares three physical models describing the PV cell (corresponding to three-, four- and five-parameter equivalent electric circuit) and two thermal models for the cell temperature estimation (NOCT and Sandia). The models were calibrated and tested towards ten monocrystalline and eight polycrystalline modules installed at SolarTechLab at Politecnico di Milano. The hourly error of the forecasted power output is usually lower than 15Wh, while NMAE{\textless}inf{\textgreater}{\%}{\textless}/inf{\textgreater} and WMAE{\textless}inf{\textgreater}{\%}{\textless}/inf{\textgreater} are in the range of 0.5{\%} and 10{\%}. Low errors, calculated with actual weather conditions, suggest that the implemented models are accurate, but they cannot be directly compared with other approaches which adopt weather forecasts. Results show that there is no clear advantage of using complex models, but the data used for the model calibration mostly affect the model accuracy. It was found that forecasted power output are more accurate using experimental data and Sandia's thermal model in monocrystalline cells type, while for the polycrystalline the data from the manufacturer and NOCT have lower errors.},
	author = {Dolara, Alberto and Leva, Sonia and Manzolini, Giampaolo},
	doi = {10.1016/j.solener.2015.06.017},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/1-s2.0-S0038092X15003254-main.pdf:pdf},
	issn = {0038092X},
	journal = {Solar Energy},
	keywords = {NMAE,PV equivalent electrical circuit,PV forecast power production,SolarTechlab,WMAE},
	mendeley-groups = {mgRL},
	pages = {83--99},
	publisher = {Elsevier Ltd},
	title = {{Comparison of different physical models for PV power output prediction}},
	url = {http://dx.doi.org/10.1016/j.solener.2015.06.017},
	volume = {119},
	year = {2015}
}

@article{Lombardi2019,
	abstract = {Energy access projects in remote off-grid areas would benefit from the adoption of a multi-energy system perspective, addressing all energy needs – not only lighting and power appliances, but also water-heating and cooking – by means of a mix of energy vectors. However, multi-energy analyses in remote areas are hindered by a lack of models allowing for the generation of multi-energy load profiles based on interview-based information characterised by high uncertainty. This study proposes a novel open-source bottom-up stochastic model specifically conceived for the generation of multi-energy loads for systems located in remote areas. The model is tested and validated against data obtained from a real system, showing a very good approximation of measured profiles, with percentage errors consistently below 2{\%} for all the selected indicators, and an improved accuracy compared to existing approaches. In particular, some innovative features – such as the possibility to define and modulate throughout the day appliances' duty cycles – seem to be determinant in marking a difference with previous approaches. This might arguably be even more beneficial for case studies characterised by a larger penetration of appliances that are subject to complex and unpredictable duty cycle behaviour.},
	author = {Lombardi, Francesco and Balderrama, Sergio and Quoilin, Sylvain and Colombo, Emanuela},
	doi = {10.1016/j.energy.2019.04.097},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/1-s2.0-S0360544219307303-main.pdf:pdf},
	issn = {03605442},
	journal = {Energy},
	keywords = {Energy demand,Load profile,Multi-energy system,Off-grid,Rural areas},
	mendeley-groups = {mgRL},
	pages = {433--444},
	publisher = {Elsevier Ltd},
	title = {{Generating high-resolution multi-energy load profiles for remote areas with an open-source stochastic model}},
	url = {https://doi.org/10.1016/j.energy.2019.04.097},
	volume = {177},
	year = {2019}
}

@misc{MGRLgit,
	author = {Cornelusse, Bertrand and Boukas, Ioannis and Elmekki, Selim},
	title = {LIfe long reinforcement learning for microgrid applications},
	year = {2019},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/bcornelusse/microgridRLsimulator}},
	commit = {}
}

@inproceedings{balderrama2018techno,
	title={Techno-economic evaluation of rural electrification in Bolivia: lessons learned from the “El Espino” micro-grid},
	author={Balderrama, S and Haderspock, Fernando and Canedo, Walter and Orellana, R and Quoilin, Sylvain},
	booktitle={ECOS 2018-Proceedings of the 31st International Conference on Efficiency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems},
	year={2018}
}

@book{bertsekas2005dynamic,
	title={Dynamic programming and optimal control},
	author={Bertsekas, Dimitri P},
	volume={1},
	number={3},
	year={2005},
	publisher={Athena scientific Belmont, MA}
}

@article{VanHasselt2016,
	abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1509.06461v3},
	author = {{Van Hasselt}, Hado and Guez, Arthur and Silver, David},
	eprint = {arXiv:1509.06461v3},
	file = {:C$\backslash$:/Users/jcbou/Desktop/1509.06461.pdf:pdf},
	isbn = {9781577357605},
	journal = {30th AAAI Conference on Artificial Intelligence, AAAI 2016},
	mendeley-groups = {mgRL},
	pages = {2094--2100},
	title = {{Deep reinforcement learning with double Q-Learning}},
	year = {2016}
}
@article{Schaul2015,
	abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
	archivePrefix = {arXiv},
	arxivId = {1511.05952},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	eprint = {1511.05952},
	file = {:C$\backslash$:/Users/jcbou/Desktop/1511.05952.pdf:pdf},
	mendeley-groups = {mgRL},
	pages = {1--21},
	title = {{Prioritized Experience Replay}},
	url = {http://arxiv.org/abs/1511.05952},
	year = {2015}
}
@article{Mnih2015,
	abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	doi = {10.1038/nature14236},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/ToRead/RL/nature14236.pdf:pdf},
	issn = {14764687},
	journal = {Nature},
	mendeley-groups = {mgRL},
	number = {7540},
	pages = {529--533},
	publisher = {Nature Publishing Group},
	title = {{Human-level control through deep reinforcement learning}},
	url = {http://dx.doi.org/10.1038/nature14236},
	volume = {518},
	year = {2015}
}

@article{watkins1992,
	title={Q-learning},
	author={Watkins, Christopher JCH and Dayan, Peter},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={279--292},
	year={1992},
	publisher={Springer}
}

@inproceedings{Schulman2015,
	author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael and Abbeel, Pieter},
	title = {{Trust Region Policy Optimization}},
	booktitle={ICML 2015-Proceedings of the 31st International Conference on Machine Learning},
	year = {2015}
}

@article{Schulman2017,
	abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a "surrogate" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},
	archivePrefix = {arXiv},
	arxivId = {1707.06347},
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	eprint = {1707.06347},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/ToRead/1707.06347.pdf:pdf},
	mendeley-groups = {mgRL},
	pages = {1--12},
	title = {{Proximal Policy Optimization Algorithms}},
	url = {http://arxiv.org/abs/1707.06347},
	year = {2017}
}

@inproceedings{sutton2000policy,
	title={Policy gradient methods for reinforcement learning with function approximation},
	author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
	booktitle={Advances in neural information processing systems},
	pages={1057--1063},
	year={2000}
}

@article{brockman2016openai,
	title={Open{AI} gym},
	author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	journal={arXiv preprint arXiv:1606.01540},
	year={2016}
}
@article{Balderrama2019,
	abstract = {Efforts towards ensuring clean and affordable electricity for all have been progressing slowly in rural, off grid areas of developing countries. In this context, hybrid microgrids may offer reliable and potentially clean electricity for isolated locations. Nevertheless, the process of planning and operation of these systems faces several challenges, often due to the uncertainties related to the renewable resources and to the stochastic nature of electricity consumption in rural contexts. This paper tackles this problem and contributes to the literature in bridging the gap between field practices and two-stage stochastic modeling approaches by identifying an open-source modeling framework which is then applied to real local data. As reference case-study, we consider a microgrid built in 2015 in Bolivia. Overall, the optimal system results from a compromise between the Net Present Cost, the peak capacity installed and the flexibility (to balance variable generation). Different approaches to size isolated microgrids are tested, with the conclusion that methods accounting for the uncertainty in both demand and renewable generation may lead to a more robust configuration with little impacts on the final cost for the community.},
	author = {Balderrama, Sergio and Lombardi, Francesco and Riva, Fabio and Canedo, Walter and Colombo, Emanuela and Quoilin, Sylvain},
	doi = {10.1016/j.energy.2019.116073},
	file = {:C$\backslash$:/Users/jcbou/Documents/PhD/Delta/literature/1-s2.0-S0360544219317682-main.pdf:pdf},
	issn = {03605442},
	journal = {Energy},
	mendeley-groups = {mgRL},
	pages = {116073},
	publisher = {Elsevier Ltd},
	title = {{A two-stage linear programming optimization framework for isolated hybrid microgrids in a rural context: The case study of the “El Espino” community}},
	url = {https://doi.org/10.1016/j.energy.2019.116073},
	volume = {188},
	year = {2019}
}

@article{sutton2012dyna,
  title={Dyna-style planning with linear function approximation and prioritized sweeping},
  author={Sutton, Richard S and Szepesv{\'a}ri, Csaba and Geramifard, Alborz and Bowling, Michael P},
  journal={arXiv preprint arXiv:1206.3285},
  year={2012}
}


@article{imani2018improving,
  title={Improving regression performance with distributional losses},
  author={Imani, Ehsan and White, Martha},
  journal={arXiv preprint arXiv:1806.04613},
  year={2018}
}


@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}


@inproceedings{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado P and Hessel, Matteo and Aslanides, John},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14322--14333},
  year={2019}
}


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{dulac2019challenges,
  title={Challenges of real-world reinforcement learning},
  author={Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
  journal={arXiv preprint arXiv:1904.12901},
  year={2019}
}


@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}


@inproceedings{kuh1991learning,
  title={Learning time-varying concepts},
  author={Kuh, Anthony and Petsche, Thomas and Rivest, Ronald L},
  booktitle={Advances in Neural Information Processing Systems},
  pages={183--189},
  year={1991}
}



@article{taylor2018forecasting,
  title={Forecasting at scale},
  author={Taylor, Sean J and Letham, Benjamin},
  journal={The American Statistician},
  volume={72},
  number={1},
  pages={37--45},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{tsymbal2004problem,
  title={The problem of concept drift: definitions and related work},
  author={Tsymbal, Alexey},
  journal={Computer Science Department, Trinity College Dublin},
  volume={106},
  number={2},
  pages={58},
  year={2004}
}


@inproceedings{lim2013reinforcement,
  title={Reinforcement learning in robust markov decision processes},
  author={Lim, Shiau Hong and Xu, Huan and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={701--709},
  year={2013}
}


@article{nilim2005robust,
  title={Robust control of Markov decision processes with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  journal={Operations Research},
  volume={53},
  number={5},
  pages={780--798},
  year={2005},
  publisher={INFORMS}
}


@inproceedings{gajane2018ucrl,
  author={Gajane, Pratik and Ortner, Ronald and Auer, Peter},
  title={A Sliding-Window Approach for Reinforcement Learning in MDPs with Arbitrarily Changing Rewards and Transitions},
  booktitle={Proceedings of the 2nd ICML/IJCAI Workshop on Lifelong Learning: A Reinforcement Learning Approach (LLARLA 2018)},
  year={2018}
}

@article{park2020reinforcement,
  title={Reinforcement Learning-based Fast Charging Control Strategy for Li-ion Batteries},
  author={Park, Saehong and Pozzi, Andrea and Whitmeyer, Michael and Joe, Won Tae and Raimondo, Davide M and Moura, Scott},
  journal={arXiv preprint arXiv:2002.02060},
  year={2020}
}


@inproceedings{lee2012intelligent,
  title={An Intelligent Battery Controller Using Bias-Corrected Q-learning.},
  author={Lee, Donghun and Powell, Warren B},
  year={2012}
}

@article{SAMADI2020106211,
title = "Decentralized multi-agent based energy management of microgrid using reinforcement learning",
journal = "International Journal of Electrical Power & Energy Systems",
volume = "122",
pages = "106211",
year = "2020",
issn = "0142-0615",
doi = "https://doi.org/10.1016/j.ijepes.2020.106211",
url = "http://www.sciencedirect.com/science/article/pii/S0142061520304877",
author = "Esmat Samadi and Ali Badri and Reza Ebrahimpour",
keywords = "Distributed energy resources, Microgrid energy management system, Multi-agent systems, Reinforcement learning",
abstract = "This paper proposes a multi-agent based decentralized energy management approach in a grid-connected microgrid (MG). The MG comprises of wind and photovoltaic resources, diesel generator, electrical energy storage, and combined heat and power generations to serve electrical and thermal loads at the lower-level of energy management system (EMS). All distributed energy resources (DERs) and customers are modelled as self-interested agents who adopt reinforcement learning to optimize their behaviours and operation costs. Based on this algorithm, agents have the capability to interact with each other in a distributed manner and find the best strategy in competitive environment. At the upper-level of EMS, there is an energy management agent that gathers the information of agents of lower-level and clears the MG electrical and thermal energy market in line with predetermined goals. Utilizing energy availability from different DERs and variety of customers’ consumption patterns, considering uncertainty of renewable generation and load consumption and taking into account technical constraint of DERs are the strengths of the presented framework. Performance of the proposed algorithm is investigated under different conditions of agents learning and using ε-greedy, soft-max and upper confidence bound methods. The simulation results verify efficacy of the proposed approach."
}

@article{foruzan2018reinforcement,
  title={Reinforcement learning approach for optimal distributed energy management in a microgrid},
  author={Foruzan, Elham and Soh, Leen-Kiat and Asgarpoor, Sohrab},
  journal={IEEE Transactions on Power Systems},
  volume={33},
  number={5},
  pages={5749--5758},
  year={2018},
  publisher={IEEE}
}

@article{shuai2020line,
  title={On-Line Scheduling of a Residential Microgrid via Monte-Carlo Tree Search and a Learned Model},
  author={Shuai, Hang and He, Haibo and Wen, Jinyu},
  journal={arXiv preprint arXiv:2005.06161},
  year={2020}
}

@misc{schrittwieser2019mastering,
    title={Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model},
    author={Julian Schrittwieser and Ioannis Antonoglou and Thomas Hubert and Karen Simonyan and Laurent Sifre and Simon Schmitt and Arthur Guez and Edward Lockhart and Demis Hassabis and Thore Graepel and Timothy Lillicrap and David Silver},
    year={2019},
    eprint={1911.08265},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{NYONGBASSEY2020116622,
title = {Reinforcement learning based adaptive power pinch analysis for energy management of stand-alone hybrid energy storage systems considering uncertainty},
journal = {Energy},
volume = {193},
pages = {116622},
year = {2020},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2019.116622},
url = {https://www.sciencedirect.com/science/article/pii/S0360544219323175},
author = {Bassey Etim Nyong-Bassey and Damian Giaouris and Charalampos Patsios and Simira Papadopoulou and Athanasios I. Papadopoulos and Sara Walker and Spyros Voutetakis and Panos Seferlis and Shady Gadoue},
keywords = {Hybrid energy storage systems, Energy management strategies, Model predictive control, Kalman filter, Reinforcement learning},
abstract = {Hybrid energy storage systems (HESS) involve synergies between multiple energy storage technologies with complementary operating features aimed at enhancing the reliability of intermittent renewable energy sources (RES). Nevertheless, coordinating HESS through optimized energy management strategies (EMS) introduces complexity. The latter has been previously addressed by the authors through a systems-level graphical EMS via Power Pinch Analysis (PoPA). Although of proven efficiency, accounting for uncertainty with PoPA has been an issue, due to the assumption of a perfect day ahead (DA) generation and load profiles forecast. This paper proposes three adaptive PoPA-based EMS, aimed at negating load demand and RES stochastic variability. Each method has its own merits such as; reduced computational complexity and improved accuracy depending on the probability density function of uncertainty. The first and simplest adaptive scheme is based on a receding horizon model predictive control framework. The second employs a Kalman filter, whereas the third is based on a machine learning algorithm. The three methods are assessed on a real isolated HESS microgrid built in Greece. In validating the proposed methods against the DA PoPA, the proposed methods all performed better with regards to violation of the energy storage operating constraints and plummeting carbon emission footprint.}
}

@article{AFRASIABI2019115873,
title = {Multi-agent microgrid energy management based on deep learning forecaster},
journal = {Energy},
volume = {186},
pages = {115873},
year = {2019},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2019.115873},
url = {https://www.sciencedirect.com/science/article/pii/S0360544219315452},
author = {Mousa Afrasiabi and Mohammad Mohammadi and Mohammad Rastegar and Amin Kargarian},
keywords = {Microgrid energy management system, Short-term forecasting, Deep learning, Convolutional neural networks, Gated recurrent unit, Alternating direction method of multipliers},
abstract = {This paper presents a multi-agent day-ahead microgrid energy management framework. The objective is to minimize energy loss and operation cost of agents, including conventional distributed generators, wind turbines, photovoltaics, demands, battery storage systems, and microgrids aggregator agent. To forecast market prices, wind generation, solar generation, and load demand, a deep learning-based approach is designed based on a combination of convolutional neural networks and gated recurrent unit. Each agent utilizes the designed learning approach and its own historical data to forecast its required parameters/data for scheduling purposes. To preserve the information privacy of agents, the alternating direction method of multipliers (ADMM) is utilized to find the optimal operating point of microgrid distributedly. To enhance the convergence performance of the distributed algorithm, an accelerated ADMM is presented based on the concept of over-relaxation. In the proposed framework, the agents do not need to share with other parties either their historical data for forecasting purposes or commercially sensitive information for scheduling purposes. The proposed framework is tested on a realistic test system. The forecast values obtained by the proposed forecasting method are compared with several other methods and the accelerated distributed algorithm is compared with the standard ADMM and analytical target cascading.}
}

@article{KOFINAS201853,
title = {Fuzzy Q-Learning for multi-agent decentralized energy management in microgrids},
journal = {Applied Energy},
volume = {219},
pages = {53-67},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2018.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0306261918303465},
author = {P. Kofinas and A.I. Dounis and G.A. Vouros},
keywords = {Energy management, Reinforcement learning (RL), Fuzzy Q-Learning, Multi-agent system (MAS), Microgrid},
abstract = {This study proposes a cooperative multi-agent system for managing the energy of a stand-alone microgrid. The multi-agent system learns to control the components of the microgrid so as this to achieve its purposes and operate effectively, by means of a distributed, collaborative reinforcement learning method in continuous actions-states space. Stand-alone microgrids present challenges regarding guaranteeing electricity supply and increasing the reliability of the system under the uncertainties introduced by the renewable power sources and the stochastic demand of the consumers. In this article we consider a microgrid that consists of power production, power consumption and power storage units: the power production group includes a Photovoltaic source, a fuel cell and a diesel generator; the power consumption group includes an electrolyzer unit, a desalination plant and a variable electrical load that represent the power consumption of a building; the power storage group includes only the Battery bank. We conjecture that a distributed multi-agent system presents specific advantages to control the microgrid components which operate in a continuous states and actions space: For this purpose we propose the use of fuzzy Q-Learning methods for agents representing microgrid components to act as independent learners, while sharing state variables to coordinate their behavior. Experimental results highlight both the effectiveness of individual agents to control system components, as well as the effectiveness of the multi-agent system to guarantee electricity supply and increase the reliability of the microgrid.}
}

@article{ROCCHETTA2019291,
title = {A reinforcement learning framework for optimal operation and maintenance of power grids},
journal = {Applied Energy},
volume = {241},
pages = {291-301},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.03.027},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919304222},
author = {R. Rocchetta and L. Bellani and M. Compare and E. Zio and E. Patelli},
keywords = {Reinforcement learning, Artificial neural networks, Prognostic and health management, Operation and maintenance, Power grid, Uncertainty},
abstract = {We develop a Reinforcement Learning framework for the optimal management of the operation and maintenance of power grids equipped with prognostics and health management capabilities. Reinforcement learning exploits the information about the health state of the grid components. Optimal actions are identified maximizing the expected profit, considering the aleatory uncertainties in the environment. To extend the applicability of the proposed approach to realistic problems with large and continuous state spaces, we use Artificial Neural Networks (ANN) tools to replace the tabular representation of the state-action value function. The non-tabular Reinforcement Learning algorithm adopting an ANN ensemble is designed and tested on the scaled-down power grid case study, which includes renewable energy sources, controllable generators, maintenance delays and prognostics and health management devices. The method strengths and weaknesses are identified by comparison to the reference Bellman’s optimally. Results show good approximation capability of Q-learning with ANN, and that the proposed framework outperforms expert-based solutions to grid operation and maintenance management.}
}

@article{XIONG2018538,
title = {Reinforcement learning-based real-time power management for hybrid energy storage system in the plug-in hybrid electric vehicle},
journal = {Applied Energy},
volume = {211},
pages = {538-548},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2017.11.072},
url = {https://www.sciencedirect.com/science/article/pii/S0306261917316707},
author = {Rui Xiong and Jiayi Cao and Quanqing Yu},
keywords = {Reinforcement learning, Power transition probability matrices, Kullback-Leibler divergence, Forgetting factor, Power management, Energy loss},
abstract = {Power allocation is a crucial issue for hybrid energy storage system (HESS) in a plug-in hybrid electric vehicle (PHEV). To obtain the best power distribution between the battery and the ultracapacitor, the reinforcement learning (RL)-based real-time power-management strategy is raised. Firstly, a long driving cycle, which includes various speed variations, is chosen, and the power transition probability matrices based on stationary Markov chain are calculated. Then, the RL algorithm is employed to obtain a control strategy aiming at minimizing the energy loss of HESS. To reduce the energy loss further, the power transition probability matrices should be updated according to the new application driving cycle and Kullback-Leibler (KL) divergence rate is used to judge when the updating of power management strategy is triggered. The conditions of different forgetting factors and KL divergence rates are discussed to seek the optimal value. A comparison between the RL-based online power management and the rule-based power management shows that the RL-based online power management strategy can lessen the energy loss effectively and the relative decrease of the total energy loss can reach 16.8%. Finally, the strategy is verified in different conditions, such as temperatures, states of health, initials of SoC and driving cycles. The results indicate that not only can the RL-based real-time power-management strategy limit the maximum discharge current and reduce the charging frequency of the battery pack, but also can decrease the energy loss and optimize the system efficiency.}
}


@inproceedings{lopes2012exploration,
  title={Exploration in model-based reinforcement learning by empirically estimating learning progress},
  author={Lopes, Manuel and Lang, Tobias and Toussaint, Marc and Oudeyer, Pierre-Yves},
  booktitle={Neural Information Processing Systems (NIPS)},
  year={2012}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{polydoros2017survey,
  title={Survey of model-based reinforcement learning: Applications on robotics},
  author={Polydoros, Athanasios S and Nalpantidis, Lazaros},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={86},
  number={2},
  pages={153--173},
  year={2017},
  publisher={Springer}
}

@incollection{SUTTON1990216,
title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
editor = {Bruce Porter and Raymond Mooney},
booktitle = {Machine Learning Proceedings 1990},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {216-224},
year = {1990},
isbn = {978-1-55860-141-3},
doi = {https://doi.org/10.1016/B978-1-55860-141-3.50030-4},
url = {https://www.sciencedirect.com/science/article/pii/B9781558601413500304},
author = {Richard S. Sutton},
abstract = {This paper extends previous work with Dyna, a class of architectures for intelligent systems based on approximating dynamic programming methods. Dyna architectures integrate trial-and-error (reinforcement) learning and execution-time planning into a single process operating alternately on the world and on a learned model of the world. In this paper, I present and show results for two Dyna architectures. The Dyna-PI architecture is based on dynamic programming's policy iteration method and can be related to existing AI ideas such as evaluation functions and universal plans (reactive systems). Using a navigation task, results are shown for a simple Dyna-PI system that simultaneously learns by trial and error, learns a world model, and plans optimal routes using the evolving world model. The Dyna-Q architecture is based on Watkins's Q-learning, a new kind of reinforcement learning. Dyna-Q uses a less familiar set of data structures than does Dyna-PI, but is arguably simpler to implement and use. We show that Dyna-Q architectures are easy to adapt for use in changing environments.}
}

@article{ZHANG20181229,
title = {Robust model predictive control for optimal energy management of island microgrids with uncertainties},
journal = {Energy},
volume = {164},
pages = {1229-1241},
year = {2018},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2018.08.200},
url = {https://www.sciencedirect.com/science/article/pii/S0360544218317365},
author = {Yan Zhang and Lijun Fu and Wanlu Zhu and Xianqiang Bao and Cang Liu},
keywords = {Robust model predictive control (RMPC), Robust linear optimization, Island microgrid, Uncertainty, Mixed integer programming},
abstract = {As the increasing penetration of wind and PV generations in island microgrids, the intermittent nature of renewable energy resources and randomness of load demands are inevitable, therefore, maintaining system stability and reliability has become a challenging issue for microgrid operators. In addition, energy storage unit and demand side management technology are widely utilized in the island microgrids to alleviate the passive impacts introduced by renewable energy resources. Nevertheless, they produce uncertainties as well. To accommodate the combined uncertainties, a two-stage robust model predictive control based optimization approach is proposed in this paper. The mixed integer quadratic programming model is established in the first operation stage to minimize the operation cost under the joint worst case of uncertainty, then an economic dispatch model is used to minimize the adjustment cost after obtaining actual data in the second operation stage. Robust linearization methods with the consideration of three types of uncertainty scenarios and uncertainty budgets are utilized in the first operation stage. Finally, the case study indicates that the proposed approach is more robust and economical than the conventional two-stage robust optimization approach, then the sensitivity of typical parameters and important units are analyzed and discussed.}
}

@article{BRUNI2016119,
title = {Energy management in a domestic microgrid by means of model predictive controllers},
journal = {Energy},
volume = {108},
pages = {119-131},
year = {2016},
note = {Sustainable Energy and Environmental Protection 2014},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2015.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0360544215010488},
author = {G. Bruni and S. Cordiner and V. Mulone and V. Sinisi and F. Spagnolo},
keywords = {Distributed generation, Microgrids, Model predictive control, Fuel cells},
abstract = {The need to increase renewable energy sources deployment and to reduce consumption of fossil fuels has led to the diffusion of small-scale DG (Distributed Generation) systems, which may be effectively integrated in micro-grids. The role of control logic in defining microgrid performances and reliability is predominant and can be improved by using advanced control logics such as the ones based on MPC (Model Predictive Control). In a previous paper, a MPC logic, based on the use of weather forecasts to improve the performances, has been applied to the analysis of power management in a domestic micro-grid system composed by: PV (Photovoltaic panels), FC (Fuel Cells) and a battery pack; in that case, the system was not affected by real uncertainties. In this paper the same system has been considered for domestic microgrid applications. The system control logic has been implemented by assuming real weather forecast as input data. DMPC and SMPC (Deterministic and Stochastic Model Predictive Control) concepts have been applied to the system and results have been compared to both MPC and to a standard RBC (Rule Based Control) logic. The impact of forecast uncertainties has been evaluated showing the advantages of a stochastic approach. In that case, the SMPC showed encouraging performances compared to standard control logics, primarily in terms of primary energy savings and downsizing potential of the power-delivering sub-systems using programmable energy sources.}
}